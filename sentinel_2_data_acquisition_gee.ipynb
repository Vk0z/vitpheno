{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio as rio\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_image_path = r\"C:\\Users\\Kostas\\Downloads\\sentinel2_images_mean_2019-04-01_to_2019-05-01-0000000000-0000000000.tif\" #OG one\n",
    "s2_image_path = r\"C:\\Users\\Kostas\\Downloads\\sentinel2_images_mean_2019-04-01_to_2019-05-01-0000000000-0000006912.tif\"\n",
    "envelopes_gdf = gpd.read_file(r\"C:\\Users\\Kostas\\Desktop\\GIMA\\Module_7\\Data\\PEP725\\After_2016_sent_from_PEP725\\pep725_outputs\\PEP725_envelopes.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rio.open(s2_image_path) as src:\n",
    "    print(src.bounds)\n",
    "    print(src.crs)\n",
    "    print(src.count)\n",
    "    src.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "envelopes_gdf.set_crs(32632, inplace=True, allow_override=True)\n",
    "envelopes_gdf.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the gdfs by year\n",
    "#envelopes_gdf_2019 = envelopes_gdf[envelopes_gdf['year'] == 2019]\n",
    "#envelopes_gdf_2020 = envelopes_gdf[envelopes_gdf['year'] == 2020]\n",
    "#envelopes_gdf_2019.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Temporal filter\n",
    "Now that everything is loaded the temporal filter should be applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract the dates from the filename of GEE S2 images\n",
    "\n",
    "def imageNamingGEEfiles(raster_path):\n",
    "    # Example file name: sentinel2_images_mean_2019-07-01_to_2019-08-01-0000006912-0000006912.tif\n",
    "    string_parts = raster_path.split(\"_\")\n",
    "    start_date = string_parts[3]\n",
    "    token = string_parts[5]\n",
    "    token_string_parts = token.split(\"-\")\n",
    "    end_date = token_string_parts[0] + \"-\" + token_string_parts[1] + \"-\" + token_string_parts[2]\n",
    "    # Save the month and year to variables\n",
    "    s2month = datetime.strptime(start_date, '%Y-%m-%d').month\n",
    "    s2year = datetime.strptime(start_date, '%Y-%m-%d').year\n",
    "    return start_date, end_date, s2month, s2year\n",
    "\n",
    "a, b, c, d = imageNamingGEEfiles(\"sentinel2_images_mean_2019-07-01_to_2019-08-01-0000006912-0000006912.tif\")\n",
    "print(a, b, c, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pathlib stuff: Path methods: anchor, parent, name, stem, suffixes\n",
    "# This can be used for easier extraction of dates from the filename\n",
    "print(\"anchor: \", Path(s2_image_path).anchor)\n",
    "print(\"parent: \", Path(s2_image_path).parent)\n",
    "print(\"name: \", Path(s2_image_path).name)\n",
    "print(\"stem: \", Path(s2_image_path).stem)\n",
    "print(\"suffixes: \", Path(s2_image_path).suffixes)\n",
    "print(\"Normal print: \", s2_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the start and end dates of the image from its name\n",
    "s2_image_start_date, s2_image_end_date, s2month, s2year = imageNamingGEEfiles(Path(s2_image_path).name)\n",
    "print(s2_image_start_date, s2_image_end_date, s2month, s2year)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________\n",
    "Datetime operations in order to do date comparisons and find all the dates that are represented in an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the date column to datetime data type\n",
    "\n",
    "envelopes_gdf['date'] = pd.to_datetime(envelopes_gdf['date'], format='%Y-%m-%d').dt.date\n",
    "# Converting the outputs to datetime.date dtype\n",
    "s2_image_start_date = datetime.strptime(s2_image_start_date, '%Y-%m-%d').date()\n",
    "s2_image_end_date = datetime.strptime(s2_image_end_date, '%Y-%m-%d').date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a mask to filter the dates that are needed\n",
    "temporal_mask = (envelopes_gdf.date > s2_image_start_date) & (envelopes_gdf.date < s2_image_end_date)\n",
    "display(envelopes_gdf.loc[temporal_mask])\n",
    "s2_image_gdf = envelopes_gdf.loc[temporal_mask]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addMonths(gdf):\n",
    "    # Convert the date to datetime type to work later\n",
    "    gdf['date'] = pd.to_datetime(gdf['date'])\n",
    "\n",
    "    # Create a Series with the month (1-12)\n",
    "    # It finds the month (int 1-12) based on the .month method of the datetime property\n",
    "    # It achieves that by mapping a lambda function on each element of the date column. Therefore the result is just the month number\n",
    "\n",
    "    getmonth = gdf['date'].map(lambda x:x.month)\n",
    "    # Another way\n",
    "    # test_df = test_df.assign(month=test_df['date'].map(lambda x: x.month))\n",
    "\n",
    "    # Merge this into the gdf\n",
    "    gdf = gdf.merge(getmonth, left_index=True, right_index=True)\n",
    "\n",
    "    # Rename the column\n",
    "    gdf.rename(columns = {'date_y':'month'}, inplace = True)\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "envelopes_gdf = addMonths(envelopes_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for indexing using specific observations\n",
    "station = 4240\n",
    "year = 2021\n",
    "month = 8\n",
    "envelopes_gdf[(envelopes_gdf['s_id'] == station) & (envelopes_gdf['year'] == year) & (envelopes_gdf['month'] == month)]\n",
    "envelopes_gdf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group observations by s_id and month, and calculate the label with the maximum frequency for each group\n",
    "freqresults_df = envelopes_gdf.groupby(['s_id', pd.Grouper(key='month'), pd.Grouper(key='year')])\\\n",
    "    .apply(lambda x: pd.Series({'Label': x['Label'].value_counts().index[0],\n",
    "                                'phase_id': x['phase_id'].value_counts().index[0]}))\\\n",
    "    .reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the column with the labels\n",
    "freqresults_df = freqresults_df.rename(columns={'Label': 'max_label', 'phase_id': 'max_phase_id'})\n",
    "\n",
    "freqresults_df.head()\n",
    "freqresults_df['max_label'].value_counts()\n",
    "freqresults_df['max_phase_id'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_image_gdf = addMonths(s2_image_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the envelopes_gdf to a list to work with the functions\n",
    "s2_image_gdf_list = s2_image_gdf.geometry.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is used to save the indices and then extract the targets directly from the gdf\n",
    "s2_image_gdf_index_list = s2_image_gdf.index.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_image_gdf_index_list[150:160]\n",
    "s2_image_gdf.iloc[150:160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(r'C:\\Users\\Kostas\\Desktop\\GIMA\\Module_7\\Data\\filtered_patches_GEE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Function to parse features from GeoDataFrame in such a manner that rasterio wants them\"\"\"\n",
    "\n",
    "def getFeatures(gdf):\n",
    "        return [json.loads(gdf.to_json())['features'][0]['geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function reads the envelope list and a raster, checks if the polygons are fully contained in the raster \n",
    "and returns 5 lists, 4 with the boundary coordinates for all the envelopes that are fully contained in the raster \n",
    "and one of their indexes from the full_index_list.\n",
    "'''\n",
    "\n",
    "def getContainedEnvelopeCoords (raster, envelope_list, full_index_list):\n",
    "    with rio.open(raster, driver='GTiff') as src:\n",
    "        raster_extent = src.bounds\n",
    "        \n",
    "        # List initialization\n",
    "        minx_list = []\n",
    "        miny_list = []\n",
    "        maxx_list = []\n",
    "        maxy_list = []\n",
    "        index_list = []\n",
    "        for i in range(0, len(envelope_list)):\n",
    "            poly_extent = envelope_list[i].bounds\n",
    "\n",
    "            # Check if the polygon is fully inside the raster's extent\n",
    "            if (poly_extent[0] >= raster_extent[0] and poly_extent[2] <= raster_extent[2] and\n",
    "                poly_extent[1] >= raster_extent[1] and poly_extent[3] <= raster_extent[3]):\n",
    "                    minx_list.append(poly_extent[0])\n",
    "                    miny_list.append(poly_extent[1])\n",
    "                    maxx_list.append(poly_extent[2])\n",
    "                    maxy_list.append(poly_extent[3])\n",
    "                    index_list.append(full_index_list[i])\n",
    "    return minx_list, miny_list, maxx_list, maxy_list, index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "This function receives a raster file (.tif) and the boundary coordinates for a polygon. \n",
    "It then clips the raster to the extent of the polygon. \n",
    "The polygon has to intersect the raster for the operation to be completed\n",
    "'''\n",
    "\n",
    "from shapely.geometry import box\n",
    "from rasterio.mask import mask\n",
    "\n",
    "def exportImage(raster, output_path, minx, miny, maxx, maxy):\n",
    "    # open the raster file (Single Band)\n",
    "    data = rio.open(raster, driver='GTiff')\n",
    "\n",
    "    # Create a bounding box from the polygon min-max coordinates    \n",
    "    bbox = box(minx, miny, maxx, maxy)\n",
    "    # Create a geodataframe with a single polygon so that it can be used with rasterio\n",
    "    geo = gpd.GeoDataFrame({'geometry': bbox}, index=[0], crs='32632')\n",
    "    # Transform the geodataframe to a GeoJSON-like object that can be used as an input in the rasterio mask function\n",
    "    coords = getFeatures(geo)\n",
    "    #print(coords)\n",
    "    \n",
    "    # Mask and crop the raster AOI where polygon overlaps the whole raster\n",
    "    out_img, out_transform = mask(data, shapes=coords, crop=True)\n",
    "    # Define resolution and more\n",
    "    out_profile = data.profile.copy()\n",
    "    \n",
    "    out_profile.update({'driver':'GTiff', 'width': out_img.shape[2],'height': out_img.shape[1], 'transform': out_transform})\n",
    "    \n",
    "    # Write the extracted raster patch to a file\n",
    "    with rio.open(output_path, 'w', **out_profile) as dst:\n",
    "        dst.write(out_img)\n",
    "    \n",
    "    # data.close()\n",
    "    # data = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minx_list, miny_list, maxx_list, maxy_list, contained_index_list = getContainedEnvelopeCoords(s2_image_path, s2_image_gdf_list, s2_image_gdf_index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list with the contained s_id's. It works\n",
    "contained_s_id_list = []\n",
    "for i in range(0, len(contained_index_list)):\n",
    "    sid = s2_image_gdf.loc[contained_index_list[i], 's_id']\n",
    "    contained_s_id_list.append(sid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combination of everything to mine the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqresults_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqresults_df[freqresults_df['s_id'] == contained_s_id_list[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = (freqresults_df['year'] == s2year) & (freqresults_df['month'] == s2month) & (freqresults_df['s_id'] == contained_s_id_list[3])\n",
    "#freqresults_df['s_id'] == contained_s_id_list[3]\n",
    "label = freqresults_df.loc[condition, 'max_label'].values[0]\n",
    "phase_id = freqresults_df.loc[condition, 'max_phase_id'].values[0]\n",
    "print(f'Station with ID {contained_s_id_list[3]}, for the year {s2year} and month {s2month} has the label {label} and phenophase with id {phase_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as above but iterating over s_ids. Works.\n",
    "for station in contained_s_id_list:\n",
    "    condition = (freqresults_df['year'] == s2year) & (freqresults_df['month'] == s2month) & (freqresults_df['s_id'] == station)\n",
    "    label = freqresults_df.loc[condition, 'max_label'].values[0]\n",
    "    phase_id = freqresults_df.loc[condition, 'max_phase_id'].values[0]\n",
    "    print(f'Station with ID {station}, for the year {s2year} and month {s2month} has the label {label} and phenophase with id {phase_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqresults_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists of the maximum frequency labels and s_ids to organise the outputs to folders\n",
    "unique_labels = freqresults_df['max_label'].unique().tolist()\n",
    "unique_phase_ids = freqresults_df['max_phase_id'].unique().tolist()\n",
    "\n",
    "# Create folder from one of the lists. Change unique_phase_ids with unique_labels depending on what you want.\n",
    "for folder in unique_phase_ids:\n",
    "    p = Path(output_dir) / str(folder)\n",
    "    path_exists = Path.exists(p)\n",
    "    if path_exists:\n",
    "        print(f'Folder {folder} already exists, skipping...')\n",
    "    else:\n",
    "        print(f'Folder {folder} does not exist, creating it...')\n",
    "        p.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debugging to find out why it saves everything as DBL\n",
    "\n",
    "print(\"Creating patches for the image: \", Path(s2_image_path).name)\n",
    "\n",
    "# Iterating over each envelope in the gdf\n",
    "# Reminder, minx_list, contained_index_list and contained_s_id_list have the same length with the same sequence.\n",
    "for i in range(0, len(minx_list)):\n",
    "    # Condition to extract the max_label and max_phase_id from the freqresults_df, based on the s_id of the contained envelope\n",
    "    condition = (freqresults_df['year'] == s2year) & (freqresults_df['month'] == s2month) & (freqresults_df['s_id'] == contained_s_id_list[i])\n",
    "    # Get the index and station id for the station with the index in the i-th position\n",
    "    station_id = contained_s_id_list[i]\n",
    "    index = contained_index_list[i]\n",
    "\n",
    "    # Get the maximum frequency label and phase_id for the current envelope based on the month and year\n",
    "    label = freqresults_df.loc[condition, 'max_label'].values[0]\n",
    "    phase_id = freqresults_df.loc[condition, 'max_phase_id'].values[0]\n",
    "    \n",
    "    output_folder = str(phase_id)\n",
    "    # Include the aforementioned information in the image name\n",
    "    output_name = os.path.join(os.path.join(output_dir, output_folder), Path(s2_image_path).stem + f'index_{index}_station_{station_id}_label_{label}_phase_id_{phase_id}.tif')\n",
    "    print(f\"\\t Patch {i+1} out of {len(minx_list) + 1}\")\n",
    "\n",
    "    # Export the patches\n",
    "    exportImage(s2_image_path, output_name, minx_list[i], miny_list[i], maxx_list[i], maxy_list[i])\n",
    "print('Patch creation completed!') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what should be the output values from the freqresults_df of the PEP725 database depending on year and month\n",
    "for i in [2017, 2018, 2019, 2020, 2021]:\n",
    "    print(f'Checking for year {i}')\n",
    "    for j in range(1,13):\n",
    "        condition = (freqresults_df['year'] == i) & (freqresults_df['month'] == j) & (freqresults_df['s_id'].isin(contained_s_id_list))\n",
    "        test_df = freqresults_df[condition]\n",
    "        print('Month:', j, ' ',test_df.max_phase_id.unique(), test_df.max_label.unique())\n",
    "    print(' ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pep725",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
