{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the buffers file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = pathlib.Path(r\"C:\\Users\\Kostas\\Desktop\\GIMA\\Module_7\\Data\\PEP725\\After_2016_sent_from_PEP725\\pep725_outputs\\PEP725_buffers.geojson\")\n",
    "buffers = gpd.read_file(path).set_crs(32632, inplace=True, allow_override=True)\n",
    "\n",
    "# Create envelopes for the buffers\n",
    "envelope_series = buffers.geometry.envelope\n",
    "envelope_series.rename('envelope_geometry', inplace=True)\n",
    "envelope_gdf = buffers.merge(envelope_series, left_index=True, right_index=True)\n",
    "envelope_gdf = envelope_gdf.drop(['geometry'], axis=1).set_geometry('envelope_geometry').rename_geometry('geometry')\n",
    "\n",
    "# Change the envelope to a list to use it later\n",
    "envelope_list = envelope_gdf.geometry.tolist()\n",
    "# Creating a list of tuples that will be used to preserve the indexing information of the GeoDataFrame.\n",
    "# This may be of use later, to get information from the GeoDataFrame and put it in the image, e.g., a label such as the class (DBL, EC, M).\n",
    "envelope_list_with_index = []\n",
    "for index, row in envelope_gdf.iterrows():\n",
    "    envelope_list_with_index.append((index, row['geometry'], row['s_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(envelope_list_with_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, <shapely.geometry.polygon.Polygon object at 0x00000195E6434A30>, 2021)\n"
     ]
    }
   ],
   "source": [
    "print(envelope_list_with_index[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s_id</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>alt</th>\n",
       "      <th>alt_dem</th>\n",
       "      <th>gss_id</th>\n",
       "      <th>genus</th>\n",
       "      <th>species</th>\n",
       "      <th>phase_id</th>\n",
       "      <th>year</th>\n",
       "      <th>day</th>\n",
       "      <th>date</th>\n",
       "      <th>Label</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5363</td>\n",
       "      <td>13.91670</td>\n",
       "      <td>54.0833</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1050100</td>\n",
       "      <td>Alnus</td>\n",
       "      <td>Alnus glutinosa</td>\n",
       "      <td>60</td>\n",
       "      <td>2017</td>\n",
       "      <td>27</td>\n",
       "      <td>2017-01-27</td>\n",
       "      <td>DBL</td>\n",
       "      <td>POLYGON ((817520.468 5999973.720, 825520.468 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1554</td>\n",
       "      <td>7.51667</td>\n",
       "      <td>51.7333</td>\n",
       "      <td>60</td>\n",
       "      <td>72</td>\n",
       "      <td>2210500</td>\n",
       "      <td>Salix</td>\n",
       "      <td>Salix caprea</td>\n",
       "      <td>60</td>\n",
       "      <td>2017</td>\n",
       "      <td>29</td>\n",
       "      <td>2017-01-29</td>\n",
       "      <td>DBL</td>\n",
       "      <td>POLYGON ((393567.206 5728416.903, 401567.206 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3120</td>\n",
       "      <td>8.68333</td>\n",
       "      <td>49.5500</td>\n",
       "      <td>140</td>\n",
       "      <td>261</td>\n",
       "      <td>1050100</td>\n",
       "      <td>Alnus</td>\n",
       "      <td>Alnus glutinosa</td>\n",
       "      <td>60</td>\n",
       "      <td>2017</td>\n",
       "      <td>31</td>\n",
       "      <td>2017-01-31</td>\n",
       "      <td>DBL</td>\n",
       "      <td>POLYGON ((473094.080 5484647.767, 481094.080 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021</td>\n",
       "      <td>8.58333</td>\n",
       "      <td>50.0000</td>\n",
       "      <td>100</td>\n",
       "      <td>101</td>\n",
       "      <td>1050100</td>\n",
       "      <td>Alnus</td>\n",
       "      <td>Alnus glutinosa</td>\n",
       "      <td>60</td>\n",
       "      <td>2017</td>\n",
       "      <td>32</td>\n",
       "      <td>2017-02-01</td>\n",
       "      <td>DBL</td>\n",
       "      <td>POLYGON ((466138.525 5534713.881, 474138.525 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1521</td>\n",
       "      <td>7.83333</td>\n",
       "      <td>51.7000</td>\n",
       "      <td>60</td>\n",
       "      <td>58</td>\n",
       "      <td>1050100</td>\n",
       "      <td>Alnus</td>\n",
       "      <td>Alnus glutinosa</td>\n",
       "      <td>60</td>\n",
       "      <td>2017</td>\n",
       "      <td>33</td>\n",
       "      <td>2017-02-02</td>\n",
       "      <td>DBL</td>\n",
       "      <td>POLYGON ((415374.473 5724316.443, 423374.473 5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   s_id       lon      lat  alt  alt_dem   gss_id  genus          species  \\\n",
       "0  5363  13.91670  54.0833    2        0  1050100  Alnus  Alnus glutinosa   \n",
       "1  1554   7.51667  51.7333   60       72  2210500  Salix     Salix caprea   \n",
       "2  3120   8.68333  49.5500  140      261  1050100  Alnus  Alnus glutinosa   \n",
       "3  2021   8.58333  50.0000  100      101  1050100  Alnus  Alnus glutinosa   \n",
       "4  1521   7.83333  51.7000   60       58  1050100  Alnus  Alnus glutinosa   \n",
       "\n",
       "   phase_id  year  day        date Label  \\\n",
       "0        60  2017   27  2017-01-27   DBL   \n",
       "1        60  2017   29  2017-01-29   DBL   \n",
       "2        60  2017   31  2017-01-31   DBL   \n",
       "3        60  2017   32  2017-02-01   DBL   \n",
       "4        60  2017   33  2017-02-02   DBL   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((817520.468 5999973.720, 825520.468 5...  \n",
       "1  POLYGON ((393567.206 5728416.903, 401567.206 5...  \n",
       "2  POLYGON ((473094.080 5484647.767, 481094.080 5...  \n",
       "3  POLYGON ((466138.525 5534713.881, 474138.525 5...  \n",
       "4  POLYGON ((415374.473 5724316.443, 423374.473 5...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "envelope_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the date column to datetime data type\n",
    "\n",
    "envelope_gdf['date'] = pd.to_datetime(envelope_gdf['date'], format='%Y-%m-%d').dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract a list with the stations.\n",
    "stations_list = envelope_gdf['s_id'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-04-20\n",
      "2022-10-22\n",
      "2020-09-21\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from zipfile import ZipFile\n",
    "import fnmatch\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "sentinel_2_directory = r\"C:\\Users\\Kostas\\Desktop\\GIMA\\Module_7\\Data\\Sentinel2_images\"\n",
    "\n",
    "# Create a list of all the Sentinel-2 zipfiles\n",
    "sentinel_2_zip_list = glob.glob(str(sentinel_2_directory) + '/*.zip', recursive=True)\n",
    "\n",
    "# Get the date from the Sentinel-2 zip archive. Returns a datetime class object\n",
    "def getS2Date(s2zip_path):\n",
    "    string_parts = s2zip_path.split(\"_\")\n",
    "    band_string = string_parts[-1]\n",
    "    band_string = band_string.replace('.zip','')\n",
    "    string_parts = band_string.split(\"T\")\n",
    "    s2_date = string_parts[0]\n",
    "    s2_time = string_parts[1]\n",
    "    s2_date = datetime.datetime.strptime(s2_date, \"%Y%m%d\").date()\n",
    "    #print(band_string)\n",
    "    #print(s2_date, s2_time)\n",
    "    return s2_date#, s2_time This is in case you want the time as well. It will be returned as a tuple\n",
    "\n",
    "for s2zip_path in sentinel_2_zip_list:\n",
    "    s2date = getS2Date(s2zip_path)\n",
    "    print(s2date)\n",
    "\n",
    "\n",
    "# Example output: 20170420T103021_B02_10m\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'date_start' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Kostas\\Documents\\GitHub\\vitpheno\\temporal_filter.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Kostas/Documents/GitHub/vitpheno/temporal_filter.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         \u001b[39myield\u001b[39;00m current_date\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Kostas/Documents/GitHub/vitpheno/temporal_filter.ipynb#X13sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         current_date \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m timedelta(days\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Kostas/Documents/GitHub/vitpheno/temporal_filter.ipynb#X13sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m dates \u001b[39m=\u001b[39m [date\u001b[39m.\u001b[39mstrftime(\u001b[39m\"\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm-\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m) \u001b[39mfor\u001b[39;00m date \u001b[39min\u001b[39;00m date_range(date_start, date_end)]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kostas/Documents/GitHub/vitpheno/temporal_filter.ipynb#X13sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(dates)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'date_start' is not defined"
     ]
    }
   ],
   "source": [
    "#from datetime import datetime, timedelta\n",
    "import datetime\n",
    "# Returns a list of dates inbetween start and end date in the format YYYY-MM-DD\n",
    "def date_range(start_date, end_date):\n",
    "    current_date = start_date\n",
    "    while current_date <= end_date:\n",
    "        yield current_date\n",
    "        current_date += timedelta(days=1)\n",
    "    \n",
    "dates = [date.strftime(\"%Y-%m-%d\") for date in date_range(date_start, date_end)]\n",
    "print(dates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data found for station ID 1554 in the given date range\n",
      "No data found for station ID 711 in the given date range\n",
      "No data found for station ID 2710 in the given date range\n",
      "No data found for station ID 1510 in the given date range\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Kostas\\Documents\\GitHub\\vitpheno\\temporal_filter.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kostas/Documents/GitHub/vitpheno/temporal_filter.ipynb#X14sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kostas/Documents/GitHub/vitpheno/temporal_filter.ipynb#X14sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m         \u001b[39m# Print a message if the filtered geodataframe is empty\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kostas/Documents/GitHub/vitpheno/temporal_filter.ipynb#X14sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo data found for station ID \u001b[39m\u001b[39m{\u001b[39;00ms_id\u001b[39m}\u001b[39;00m\u001b[39m in the given date range\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Kostas/Documents/GitHub/vitpheno/temporal_filter.ipynb#X14sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m     results_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mconcat(df_list, ignore_index\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kostas/Documents/GitHub/vitpheno/temporal_filter.ipynb#X14sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m \u001b[39m# Concatenate the filtered data from all stations into a single geodataframe\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kostas/Documents/GitHub/vitpheno/temporal_filter.ipynb#X14sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m final_gdf \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat(results)\n",
      "File \u001b[1;32mc:\\Users\\Kostas\\anaconda3\\envs\\pep725\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Kostas\\anaconda3\\envs\\pep725\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:381\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[39mConcatenate pandas objects along a particular axis.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[39m1   3   4\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    368\u001b[0m op \u001b[39m=\u001b[39m _Concatenator(\n\u001b[0;32m    369\u001b[0m     objs,\n\u001b[0;32m    370\u001b[0m     axis\u001b[39m=\u001b[39maxis,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    378\u001b[0m     sort\u001b[39m=\u001b[39msort,\n\u001b[0;32m    379\u001b[0m )\n\u001b[1;32m--> 381\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mget_result()\n",
      "File \u001b[1;32mc:\\Users\\Kostas\\anaconda3\\envs\\pep725\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:616\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    612\u001b[0m             indexers[ax] \u001b[39m=\u001b[39m obj_labels\u001b[39m.\u001b[39mget_indexer(new_labels)\n\u001b[0;32m    614\u001b[0m     mgrs_indexers\u001b[39m.\u001b[39mappend((obj\u001b[39m.\u001b[39m_mgr, indexers))\n\u001b[1;32m--> 616\u001b[0m new_data \u001b[39m=\u001b[39m concatenate_managers(\n\u001b[0;32m    617\u001b[0m     mgrs_indexers, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnew_axes, concat_axis\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbm_axis, copy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy\n\u001b[0;32m    618\u001b[0m )\n\u001b[0;32m    619\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy:\n\u001b[0;32m    620\u001b[0m     new_data\u001b[39m.\u001b[39m_consolidate_inplace()\n",
      "File \u001b[1;32mc:\\Users\\Kostas\\anaconda3\\envs\\pep725\\lib\\site-packages\\pandas\\core\\internals\\concat.py:199\u001b[0m, in \u001b[0;36mconcatenate_managers\u001b[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[39mreturn\u001b[39;00m _concatenate_array_managers(mgrs_indexers, axes, concat_axis, copy)\n\u001b[0;32m    197\u001b[0m mgrs_indexers \u001b[39m=\u001b[39m _maybe_reindex_columns_na_proxy(axes, mgrs_indexers)\n\u001b[1;32m--> 199\u001b[0m concat_plans \u001b[39m=\u001b[39m [\n\u001b[0;32m    200\u001b[0m     _get_mgr_concatenation_plan(mgr, indexers) \u001b[39mfor\u001b[39;00m mgr, indexers \u001b[39min\u001b[39;00m mgrs_indexers\n\u001b[0;32m    201\u001b[0m ]\n\u001b[0;32m    202\u001b[0m concat_plan \u001b[39m=\u001b[39m _combine_concat_plans(concat_plans, concat_axis)\n\u001b[0;32m    203\u001b[0m blocks \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\Kostas\\anaconda3\\envs\\pep725\\lib\\site-packages\\pandas\\core\\internals\\concat.py:200\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[39mreturn\u001b[39;00m _concatenate_array_managers(mgrs_indexers, axes, concat_axis, copy)\n\u001b[0;32m    197\u001b[0m mgrs_indexers \u001b[39m=\u001b[39m _maybe_reindex_columns_na_proxy(axes, mgrs_indexers)\n\u001b[0;32m    199\u001b[0m concat_plans \u001b[39m=\u001b[39m [\n\u001b[1;32m--> 200\u001b[0m     _get_mgr_concatenation_plan(mgr, indexers) \u001b[39mfor\u001b[39;00m mgr, indexers \u001b[39min\u001b[39;00m mgrs_indexers\n\u001b[0;32m    201\u001b[0m ]\n\u001b[0;32m    202\u001b[0m concat_plan \u001b[39m=\u001b[39m _combine_concat_plans(concat_plans, concat_axis)\n\u001b[0;32m    203\u001b[0m blocks \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\Kostas\\anaconda3\\envs\\pep725\\lib\\site-packages\\pandas\\core\\internals\\concat.py:294\u001b[0m, in \u001b[0;36m_get_mgr_concatenation_plan\u001b[1;34m(mgr, indexers)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    280\u001b[0m \u001b[39mConstruct concatenation plan for given block manager and indexers.\u001b[39;00m\n\u001b[0;32m    281\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    290\u001b[0m \n\u001b[0;32m    291\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    292\u001b[0m \u001b[39m# Calculate post-reindex shape , save for item axis which will be separate\u001b[39;00m\n\u001b[0;32m    293\u001b[0m \u001b[39m# for each block anyway.\u001b[39;00m\n\u001b[1;32m--> 294\u001b[0m mgr_shape_list \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(mgr\u001b[39m.\u001b[39;49mshape)\n\u001b[0;32m    295\u001b[0m \u001b[39mfor\u001b[39;00m ax, indexer \u001b[39min\u001b[39;00m indexers\u001b[39m.\u001b[39mitems():\n\u001b[0;32m    296\u001b[0m     mgr_shape_list[ax] \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(indexer)\n",
      "File \u001b[1;32mc:\\Users\\Kostas\\anaconda3\\envs\\pep725\\lib\\site-packages\\pandas\\core\\internals\\base.py:56\u001b[0m, in \u001b[0;36mDataManager.shape\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[0;32m     55\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mshape\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Shape:\n\u001b[1;32m---> 56\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39;49m(\u001b[39mlen\u001b[39;49m(ax) \u001b[39mfor\u001b[39;49;00m ax \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maxes)\n",
      "File \u001b[1;32mc:\\Users\\Kostas\\anaconda3\\envs\\pep725\\lib\\site-packages\\pandas\\core\\internals\\base.py:56\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[0;32m     55\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mshape\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Shape:\n\u001b[1;32m---> 56\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(\u001b[39mlen\u001b[39m(ax) \u001b[39mfor\u001b[39;00m ax \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# New try 15 feb\n",
    "def get_data(station, vegetation_class, start_date, end_date):\n",
    "    pass\n",
    "def calc_target_highest_freq(data):\n",
    "    pass\n",
    "\n",
    "\n",
    "stations = []\n",
    "veg_classes = []\n",
    "for i_id in range(0, len(sentinel_2_zip_list) - 1):\n",
    "    image_1 = sentinel_2_zip_list[i_id]\n",
    "    image_2 = sentinel_2_zip_list[i_id + 1]\n",
    "\n",
    "    date_start = getS2Date(image_1)\n",
    "    date_end = getS2Date(image_2)\n",
    "\n",
    "\n",
    "    # Trying\n",
    "    results = []\n",
    "    # Create an empty dataframe to store the results\n",
    "    #freqresults_df = pd.DataFrame(columns=['s_id', 'max_label'])\n",
    "    df_list = []\n",
    "    # Iterate over the station IDs\n",
    "    for s_id in stations_list:\n",
    "        # Filter the geodataframe to include only the rows with the current station ID\n",
    "        # mask is a boolean Series, with True in the places where the station IDs match.\n",
    "        mask = envelope_gdf['s_id'] == s_id\n",
    "        \n",
    "        # Filter the geodataframe to include only the rows with dates between 'date_start' and 'date_end'\n",
    "        # Now, the dates between date_start and date_end are assigned a True value\n",
    "        # Because &= is used, the ultimate values that kept are the ones that meet both the station matching and the date matching criteria\n",
    "        # The mask is then updated to be used next\n",
    "        mask &= (envelope_gdf['date'] >= date_start) & (envelope_gdf['date'] <= date_end)\n",
    "        \n",
    "        # Extract the relevant columns for the filtered rows. Here, the mask is used as an index because it shares the same indices with envelope_gdf\n",
    "        # This way the only data that are passed are the ones for which the criteria mentioned above match.\n",
    "        filtered_data = envelope_gdf.loc[mask, ['s_id', 'date', 'Label', 'phase_id']]\n",
    "\n",
    "        if not filtered_data.empty:\n",
    "    \n",
    "            # Group the filtered geodataframe by station ID and label, and count the frequency of each label\n",
    "            label_counts = filtered_data.groupby(['s_id', 'Label']).size().reset_index(name='count')\n",
    "            \n",
    "            # Find the label that has the highest frequency for the current station ID\n",
    "            max_label = label_counts.loc[label_counts['s_id'] == s_id, 'Label'][label_counts.loc[label_counts['s_id'] == s_id, 'count'].idxmax()]\n",
    "            # Print the result for the current station ID\n",
    "            #print(f\"For station ID {s_id}, the label with the highest frequency is '{max_label}'\")\n",
    "             # Add the result to the results dataframe\n",
    "            #results_df = freqresults_df.append({'s_id': s_id, 'max_label': max_label}, ignore_index=True)\n",
    "\n",
    "            # Create a new dataframe with the current station ID and the label with the highest frequency\n",
    "            result_df = pd.DataFrame({'s_id': [s_id], 'max_label': [max_label]})\n",
    "\n",
    "            # Add the new dataframe to the list\n",
    "            df_list.append(result_df)\n",
    "        else:\n",
    "            # Print a message if the filtered geodataframe is empty\n",
    "            #print(f\"No data found for station ID {s_id} in the given date range\")\n",
    "        results_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "    # Concatenate the filtered data from all stations into a single geodataframe\n",
    "    final_gdf = pd.concat(results)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s_id</th>\n",
       "      <th>max_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5363</td>\n",
       "      <td>DBL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3120</td>\n",
       "      <td>DBL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021</td>\n",
       "      <td>DBL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1521</td>\n",
       "      <td>DBL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1710</td>\n",
       "      <td>DBL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   s_id max_label\n",
       "0  5363       DBL\n",
       "1  3120       DBL\n",
       "2  2021       DBL\n",
       "3  1521       DBL\n",
       "4  1710       DBL"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s_id</th>\n",
       "      <th>date</th>\n",
       "      <th>Label</th>\n",
       "      <th>phase_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11929</th>\n",
       "      <td>5363</td>\n",
       "      <td>2017-05-11</td>\n",
       "      <td>DBL</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12641</th>\n",
       "      <td>5363</td>\n",
       "      <td>2017-05-14</td>\n",
       "      <td>DBL</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12642</th>\n",
       "      <td>5363</td>\n",
       "      <td>2017-05-14</td>\n",
       "      <td>DBL</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12643</th>\n",
       "      <td>5363</td>\n",
       "      <td>2017-05-14</td>\n",
       "      <td>DBL</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13513</th>\n",
       "      <td>5363</td>\n",
       "      <td>2017-05-18</td>\n",
       "      <td>DBL</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       s_id        date Label  phase_id\n",
       "11929  5363  2017-05-11   DBL        60\n",
       "12641  5363  2017-05-14   DBL        11\n",
       "12642  5363  2017-05-14   DBL        11\n",
       "12643  5363  2017-05-14   DBL        60\n",
       "13513  5363  2017-05-18   DBL        60"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO next after meeting with Mahdi 15 Feb\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "final_res = pd.DataFrame()\n",
    "\n",
    "unique_dates = pd.unique(final_res.date)\n",
    "\n",
    "def get_image_paths(date):\n",
    "    image_paths = []\n",
    "    # load\n",
    "    return image_paths\n",
    "\n",
    "def load_image(path):\n",
    "    pass\n",
    "\n",
    "for d in unique_dates:\n",
    "    image_paths = get_image_paths(d)\n",
    "\n",
    "    for p in image_paths:\n",
    "         image = load_image(p)\n",
    "\n",
    "        res_for_the_image = final_res[#Filter based the boundary of the image and date d]\n",
    "\n",
    "        # iterate over stations within res_for_the_image\n",
    "        # patch for the station\n",
    "        # save the patch into the correct folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeslot 1: 2017-04-20 2022-10-22\n",
      "Timeslot 2: 2022-10-22 2020-09-21\n"
     ]
    }
   ],
   "source": [
    "def get_data(station, vegetation_class, start_date, end_date):\n",
    "    data = [station, ]\n",
    "\n",
    "def calc_target_highest_freq(data):\n",
    "    pass\n",
    "\n",
    "\n",
    "stations = []\n",
    "veg_classes = []\n",
    "for i_id in range(0, len(sentinel_2_zip_list) - 1):\n",
    "    image_1 = sentinel_2_zip_list[i_id]\n",
    "    image_2 = sentinel_2_zip_list[i_id + 1]\n",
    "\n",
    "    date_start = getS2Date(image_1)\n",
    "    date_end = getS2Date(image_2)\n",
    "    dates = [date.strftime(\"%Y-%m-%d\") for date in date_range(date_start, date_end)]\n",
    "    print(f'Timeslot {i_id+1}:', date_start, date_end)\n",
    "    data_list = []\n",
    "    for s in range(0, len(stations_list)):\n",
    "            for d in range(0, len(dates)):\n",
    "                if dates[d] == dates_list[d]:\n",
    "                    data_list = [stations_list[s], veg_classes_list[s], dates_list[s]]\n",
    "                    print(data_list)\n",
    "            # data = get_data(s, v, date_start, date_end)\n",
    "            # target = calc_target_highest_freq(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-04-20 2022-10-22\n",
      "2017-04-20\n"
     ]
    }
   ],
   "source": [
    "image_1 = sentinel_2_zip_list[0]\n",
    "image_2 = sentinel_2_zip_list[1]\n",
    "\n",
    "date_start = getS2Date(image_1)\n",
    "date_end = getS2Date(image_2)\n",
    "print(date_start, date_end)\n",
    "date_range(date_start, date_end)\n",
    "# Create a list with all the inbetween dates\n",
    "dates = [date.strftime(\"%Y-%m-%d\") for date in date_range(date_start, date_end)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-04-20\n",
      "<class 'datetime.date'>\n"
     ]
    }
   ],
   "source": [
    "date_start = str(getS2Date(sentinel_2_zip_list[0]))\n",
    "date_end = str(getS2Date(sentinel_2_zip_list[1]))\n",
    "\n",
    "a = dates[0]\n",
    "a = datetime.datetime.strptime(a, \"%Y-%m-%d\").date()\n",
    "print(a)\n",
    "print(type(a))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pep725",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "87013bfe7793781dd931ded083f6d345173d317406dd371cb864879c5f49f73e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
